{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "387ca03e8d7b4201b22660f462482644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07b5334f705f436fa7375cf697d9393c",
              "IPY_MODEL_e04ffa10e4f144c6bcca8341950f40bd",
              "IPY_MODEL_e7e2a464d8b647318044b21f7fe957ca"
            ],
            "layout": "IPY_MODEL_0dfdf9ed96514a2bad0b12665b7ed313"
          }
        },
        "07b5334f705f436fa7375cf697d9393c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f6b15cfad547178ad2007b9bcb6ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_92448b556e75482f99e53cb4a6bdbc6b",
            "value": "100%"
          }
        },
        "e04ffa10e4f144c6bcca8341950f40bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cd9d216e4945679d69f1f384d1a032",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b929c1e303f749319572b352f3ba7f4f",
            "value": 10
          }
        },
        "e7e2a464d8b647318044b21f7fe957ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039d1e1514ff4c908fbf366b8e334de3",
            "placeholder": "​",
            "style": "IPY_MODEL_43be87711b4a4720bc9ec63ef3afd7d4",
            "value": " 10/10 [32:23&lt;00:00, 194.01s/it]"
          }
        },
        "0dfdf9ed96514a2bad0b12665b7ed313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f6b15cfad547178ad2007b9bcb6ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92448b556e75482f99e53cb4a6bdbc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34cd9d216e4945679d69f1f384d1a032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b929c1e303f749319572b352f3ba7f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "039d1e1514ff4c908fbf366b8e334de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43be87711b4a4720bc9ec63ef3afd7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GraphSAGE-based Heterogeneous Graph Recommendation System**"
      ],
      "metadata": {
        "id": "CDsSjG9kpPBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPkPc9TCHx_I",
        "outputId": "775e5684-f240-4fdf-9d8f-c7bb6f34e098"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ast\n",
        "from collections import defaultdict\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.nn import HeteroConv, SAGEConv, RGCNConv, Linear\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    ndcg_score,\n",
        ")\n",
        "from typing import Dict, Any, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "sns.set_palette(sns.color_palette('CMRmap'))\n",
        "\n",
        "path = 'graph_data'\n",
        "\n",
        "with zipfile.ZipFile('graph_data.zip', 'r') as zf:\n",
        "    zf.extractall(path)\n"
      ],
      "metadata": {
        "id": "-01eSZtI02bR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**\n",
        "\n",
        "Load all node features and edge lists for heterogeneous graph construction"
      ],
      "metadata": {
        "id": "rpGfiKBCphJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yIq9xvSw0oqu"
      },
      "outputs": [],
      "source": [
        "df_connections_user_stats = pd.read_csv(f'{path}/user_stats.csv')\n",
        "df_connections_movie_features = pd.read_csv(f'{path}/movie_features.csv')\n",
        "df_connections_movie_genre = pd.read_csv(f'{path}/movie_genre_edges.csv')\n",
        "df_connections_movie_actor = pd.read_csv(f'{path}/movie_actor_edges.csv')\n",
        "df_connections_movie_director = pd.read_csv(f'{path}/movie_director_edges.csv')\n",
        "df_connections_user_movie = pd.read_csv(f'{path}/user_movie_edges.csv')\n",
        "df_connections_actors = pd.read_csv(f'{path}/actors.csv')\n",
        "df_connections_directors = pd.read_csv(f'{path}/directors.csv')\n",
        "df_connections_genres = pd.read_csv(f'{path}/genres.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Movies: {df_connections_movie_features.shape}')\n",
        "print(f'Users: {df_connections_user_stats.shape}')\n",
        "print(f'Directors: {df_connections_directors.shape}')\n",
        "print(f'Actors: {df_connections_actors.shape}')\n",
        "print(f'Genres: {df_connections_genres.shape}')\n",
        "print(f'Movie-genre links: {df_connections_movie_genre.shape}')\n",
        "print(f'Movie-actor links: {df_connections_movie_actor.shape}')\n",
        "print(f'Movie-director links: {df_connections_movie_director.shape}')\n",
        "print(f'User-movie links: {df_connections_user_movie.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcZHkPl2K3se",
        "outputId": "6754310d-4372-4a3a-ea36-39d404d6de27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies: (16409, 4)\n",
            "Users: (75680, 4)\n",
            "Directors: (1741, 3)\n",
            "Actors: (2517, 4)\n",
            "Genres: (20, 2)\n",
            "Movie-genre links: (38491, 2)\n",
            "Movie-actor links: (48106, 4)\n",
            "Movie-director links: (10570, 2)\n",
            "User-movie links: (2505904, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create mapping dictionaries: original IDs -> consecutive indices for all node types"
      ],
      "metadata": {
        "id": "HR2BbHPIpy2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_id_to_idx = {movie_id: idx for idx, movie_id in enumerate(df_connections_movie_features['movie_id'].unique())}\n",
        "\n",
        "user_id_to_idx = {user_id: idx for idx, user_id in enumerate(df_connections_user_stats['user_id'].unique())}\n",
        "\n",
        "director_id_to_idx = {director_id: idx for idx, director_id in\n",
        "                      enumerate(df_connections_directors['director_id'].unique())}\n",
        "\n",
        "actor_id_to_idx = {actor_id: idx for idx, actor_id in enumerate(df_connections_actors['actor_id'].unique())}\n",
        "\n",
        "genre_id_to_idx = {genre_id: idx for idx, genre_id in enumerate(df_connections_genres['genre_id'].unique())}\n",
        "\n",
        "print(f'Number of movies: {len(movie_id_to_idx)}')\n",
        "print(f'Number of users: {len(user_id_to_idx)}')\n",
        "print(f'Number of directors: {len(director_id_to_idx)}')\n",
        "print(f'Number of actors: {len(actor_id_to_idx)}')\n",
        "print(f'Number of genres: {len(genre_id_to_idx)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z0IpddTMImt",
        "outputId": "6463c4e5-4d4b-483b-ea21-d5dbe196022b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of movies: 16409\n",
            "Number of users: 75680\n",
            "Number of directors: 1741\n",
            "Number of actors: 2517\n",
            "Number of genres: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Subgraph Construction Pipeline**\n",
        "\n",
        "This function builds a heterogeneous graph subgraph centered around selected users, preparing data for GraphSAGE training.\n",
        "\n",
        "### **Main Parameters**\n",
        "- **`user_ids`**: Target users to build the subgraph around (central nodes)\n",
        "- **`num_negatives`**: Number of negative samples for training (200 by default) - affects training data balance\n",
        "- **DataFrames**: Feature tables and edge lists for all entity types\n",
        "\n",
        "### **Pipeline Stages**\n",
        "\n",
        "#### **1. Data Filtering & Propagation**\n",
        "- **Step 1**: Filter user-related data based on `user_ids`\n",
        "- **Step 2**: Propagate filtering to connected movies via user-movie edges\n",
        "- **Step 3**: Further propagate to related entities (actors, directors, genres)\n",
        "- **Result**: A connected subgraph containing only relevant entities\n",
        "\n",
        "#### **2. Feature Engineering & Normalization**\n",
        "- **Numerical features**: Standardized using `StandardScaler` for:\n",
        "  - Movie metrics (`vote_average`, `vote_count`, `popularity`)\n",
        "  - User statistics (`num_ratings`, `avg_rating`, `activity_days`)\n",
        "  - Actor/director metrics (`total_films`, `avg_order`)\n",
        "- **Categorical encoding**:\n",
        "  - Gender (directors/actors): One-hot encoded (3 categories: 0,1,2)\n",
        "  - Genres: One-hot encoded per unique genre ID\n",
        "\n",
        "#### **3. ID Remapping & Graph Initialization**\n",
        "- Creates sequential index mappings for each node type\n",
        "- Initializes `HeteroData` object with:\n",
        "  - `num_nodes` defined for each entity type\n",
        "  - Maintains original ID to index mapping for reference\n",
        "\n",
        "#### **4. Node Feature Assignment**\n",
        "- For each entity type, extracts normalized features\n",
        "- Maps features to corresponding node indices\n",
        "\n",
        "#### **5. Edge Construction**\n",
        "- Builds five relationship types with optional weights:\n",
        "  1. `('user', 'rates', 'movie')` - with rating weights\n",
        "  2. `('movie', 'has_genre', 'genre')`\n",
        "  3. `('movie', 'has_director', 'director')`\n",
        "  4. `('movie', 'has_actor', 'actor')` - with role weight\n",
        "\n",
        "#### **6. Bidirectional Edge Addition**\n",
        "- Creates reverse edges for message passing in both directions\n",
        "- Reverse edges follow pattern: `('genre', 'rev_has_genre', 'movie')`\n",
        "\n",
        "### **Output Structure**\n",
        "Returns a tuple containing:\n",
        "1. **`data`**: PyG HeteroData object\n",
        "2. **`mappings`**: ID-to-index dictionaries for all entity types\n",
        "3. **`df_user_movie_sub`**: Filtered user-movie interactions for training"
      ],
      "metadata": {
        "id": "GsFfkyZJKdjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_subgraph_for_users(\n",
        "        user_ids,\n",
        "        df_user_movie,\n",
        "        df_movie_features,\n",
        "        df_user_stats,\n",
        "        df_movie_genre,\n",
        "        df_movie_actor,\n",
        "        df_movie_director,\n",
        "        df_actors,\n",
        "        df_directors,\n",
        "        df_genres,\n",
        "        num_negatives=200\n",
        "):\n",
        "    selected_users = set(user_ids)\n",
        "    df_user_stats_sub = df_user_stats[df_user_stats['user_id'].isin(selected_users)].copy()\n",
        "\n",
        "    df_user_movie_sub = df_user_movie[df_user_movie['user_id'].isin(selected_users)].copy()\n",
        "    selected_movie_ids = set(df_user_movie_sub['movie_id'].unique())\n",
        "\n",
        "    df_movie_features_sub = df_movie_features[df_movie_features['movie_id'].isin(selected_movie_ids)].copy()\n",
        "    df_movie_genre_sub = df_movie_genre[df_movie_genre['movie_id'].isin(selected_movie_ids)].copy()\n",
        "    df_movie_actor_sub = df_movie_actor[df_movie_actor['movie_id'].isin(selected_movie_ids)].copy()\n",
        "    df_movie_director_sub = df_movie_director[df_movie_director['movie_id'].isin(selected_movie_ids)].copy()\n",
        "\n",
        "    selected_genre_ids = set(df_movie_genre_sub['genre_id'].unique())\n",
        "    selected_actor_ids = set(df_movie_actor_sub['actor_id'].unique())\n",
        "    selected_director_ids = set(df_movie_director_sub['director_id'].unique())\n",
        "\n",
        "    df_genres_sub = df_genres[df_genres['genre_id'].isin(selected_genre_ids)].copy()\n",
        "    df_actors_sub = df_actors[df_actors['actor_id'].isin(selected_actor_ids)].copy()\n",
        "    df_directors_sub = df_directors[df_directors['director_id'].isin(selected_director_ids)].copy()\n",
        "\n",
        "    print(f'\\nSizes of filtered data:')\n",
        "    print(f'Users: {df_user_stats_sub.shape[0]}')\n",
        "    print(f'Movies: {df_movie_features_sub.shape[0]}')\n",
        "    print(f'User-movie links: {df_user_movie_sub.shape[0]}')\n",
        "    print(f'Actors: {df_actors_sub.shape[0]}')\n",
        "    print(f'Directors: {df_directors_sub.shape[0]}')\n",
        "    print(f'Genres: {df_genres_sub.shape[0]}')\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    movie_num_cols = ['vote_average', 'vote_count', 'popularity']\n",
        "    if len(df_movie_features_sub) > 0:\n",
        "        df_movie_features_sub[movie_num_cols] = scaler.fit_transform(\n",
        "            df_movie_features_sub[movie_num_cols].fillna(0)\n",
        "        )\n",
        "\n",
        "    user_num_cols = ['num_ratings', 'avg_rating', 'activity_days']\n",
        "    if len(df_user_stats_sub) > 0:\n",
        "        df_user_stats_sub[user_num_cols] = scaler.fit_transform(\n",
        "            df_user_stats_sub[user_num_cols].fillna(0)\n",
        "        )\n",
        "\n",
        "    if len(df_directors_sub) > 0:\n",
        "        df_directors_sub['total_films'] = scaler.fit_transform(\n",
        "            df_directors_sub[['total_films']].fillna(0)\n",
        "        )\n",
        "\n",
        "    actor_num_cols = ['total_films', 'avg_order']\n",
        "    if len(df_actors_sub) > 0:\n",
        "        df_actors_sub[actor_num_cols] = scaler.fit_transform(\n",
        "            df_actors_sub[actor_num_cols].fillna(0)\n",
        "        )\n",
        "\n",
        "    gender_encoder = OneHotEncoder(sparse_output=False, categories=[[0, 1, 2]], handle_unknown='ignore')\n",
        "    if len(df_directors_sub) > 0:\n",
        "        gender_dir_encoded = gender_encoder.fit_transform(df_directors_sub[['gender']])\n",
        "        gender_dir_df = pd.DataFrame(gender_dir_encoded,\n",
        "                                     columns=['gender_0', 'gender_1', 'gender_2'])\n",
        "        df_directors_sub = pd.concat([df_directors_sub.reset_index(drop=True),\n",
        "                                      gender_dir_df], axis=1)\n",
        "        df_directors_sub = df_directors_sub.drop('gender', axis=1)\n",
        "\n",
        "    if len(df_actors_sub) > 0:\n",
        "        gender_act_encoded = gender_encoder.transform(df_actors_sub[['gender']])\n",
        "        gender_act_df = pd.DataFrame(gender_act_encoded,\n",
        "                                     columns=['gender_0', 'gender_1', 'gender_2'])\n",
        "        df_actors_sub = pd.concat([df_actors_sub.reset_index(drop=True),\n",
        "                                   gender_act_df], axis=1)\n",
        "        df_actors_sub = df_actors_sub.drop('gender', axis=1)\n",
        "\n",
        "    if len(df_genres_sub) > 0:\n",
        "        genre_encoder = OneHotEncoder(sparse_output=False)\n",
        "        genre_encoded = genre_encoder.fit_transform(df_genres_sub[['genre_id']])\n",
        "        genre_cols = [f'genre_{int(i)}' for i in genre_encoder.categories_[0]]\n",
        "        genre_df = pd.DataFrame(genre_encoded, columns=genre_cols)\n",
        "        df_genres_sub = pd.concat([df_genres_sub.reset_index(drop=True),\n",
        "                                   genre_df], axis=1)\n",
        "        df_genres_sub = df_genres_sub.drop('genre_name', axis=1)\n",
        "\n",
        "    mappings = {}\n",
        "    mappings['user'] = {user_id: idx for idx, user_id in enumerate(df_user_stats_sub['user_id'].unique())}\n",
        "    mappings['movie'] = {movie_id: idx for idx, movie_id in enumerate(df_movie_features_sub['movie_id'].unique())}\n",
        "    mappings['actor'] = {actor_id: idx for idx, actor_id in enumerate(df_actors_sub['actor_id'].unique())}\n",
        "    mappings['director'] = {director_id: idx for idx, director_id in\n",
        "                            enumerate(df_directors_sub['director_id'].unique())}\n",
        "    mappings['genre'] = {genre_id: idx for idx, genre_id in enumerate(df_genres_sub['genre_id'].unique())}\n",
        "\n",
        "    data = HeteroData()\n",
        "    data['user'].num_nodes = len(mappings['user'])\n",
        "    data['movie'].num_nodes = len(mappings['movie'])\n",
        "    data['actor'].num_nodes = len(mappings['actor'])\n",
        "    data['director'].num_nodes = len(mappings['director'])\n",
        "    data['genre'].num_nodes = len(mappings['genre'])\n",
        "\n",
        "    def add_node_features(df, node_type, id_col, mapping, data_obj):\n",
        "        if len(df) == 0:\n",
        "            return\n",
        "\n",
        "        features_list = []\n",
        "        feature_cols = [col for col in df.columns if col != id_col]\n",
        "        sorted_ids = sorted(mapping.keys(), key=lambda x: mapping[x])\n",
        "        for node_id in sorted_ids:\n",
        "            row = df[df[id_col] == node_id]\n",
        "            if len(row) > 0:\n",
        "                features = row[feature_cols].values[0].astype(np.float32)\n",
        "                features_list.append(features)\n",
        "            else:\n",
        "                features_list.append(np.zeros(len(feature_cols), dtype=np.float32))\n",
        "        data_obj[node_type].x = torch.tensor(np.array(features_list), dtype=torch.float32)\n",
        "\n",
        "    add_node_features(df_user_stats_sub, 'user', 'user_id', mappings['user'], data)\n",
        "    add_node_features(df_movie_features_sub, 'movie', 'movie_id', mappings['movie'], data)\n",
        "    add_node_features(df_actors_sub, 'actor', 'actor_id', mappings['actor'], data)\n",
        "    add_node_features(df_directors_sub, 'director', 'director_id', mappings['director'], data)\n",
        "    add_node_features(df_genres_sub, 'genre', 'genre_id', mappings['genre'], data)\n",
        "\n",
        "    def add_edges(df, source_type, target_type, source_col, target_col,\n",
        "                  edge_type_name, data_obj, mappings_dict, weight_col=None):\n",
        "        if len(df) == 0:\n",
        "            return\n",
        "\n",
        "        edges = []\n",
        "        weights = [] if weight_col is not None else None\n",
        "        for _, row in df.iterrows():\n",
        "            source_idx = mappings_dict[source_type].get(row[source_col])\n",
        "            target_idx = mappings_dict[target_type].get(row[target_col])\n",
        "            if source_idx is not None and target_idx is not None:\n",
        "                edges.append([source_idx, target_idx])\n",
        "                if weight_col is not None:\n",
        "                    weights.append(row[weight_col])\n",
        "\n",
        "        if edges:\n",
        "            edge_tensor = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "            data_obj[source_type, edge_type_name, target_type].edge_index = edge_tensor\n",
        "            if weights is not None:\n",
        "                data_obj[source_type, edge_type_name, target_type].edge_weight = torch.tensor(\n",
        "                    weights, dtype=torch.float32\n",
        "                )\n",
        "\n",
        "    add_edges(df_user_movie_sub, 'user', 'movie', 'user_id', 'movie_id',\n",
        "              'rates', data, mappings, weight_col='rating')\n",
        "    add_edges(df_movie_genre_sub, 'movie', 'genre', 'movie_id', 'genre_id',\n",
        "              'has_genre', data, mappings)\n",
        "    add_edges(df_movie_director_sub, 'movie', 'director', 'movie_id', 'director_id',\n",
        "              'has_director', data, mappings)\n",
        "    add_edges(df_movie_actor_sub, 'movie', 'actor', 'movie_id', 'actor_id',\n",
        "              'has_actor', data, mappings, weight_col='weight')\n",
        "\n",
        "    edge_types_to_reverse = [\n",
        "        ('movie', 'has_genre', 'genre'),\n",
        "        ('movie', 'has_director', 'director'),\n",
        "        ('movie', 'has_actor', 'actor'),\n",
        "        ('user', 'rates', 'movie')\n",
        "    ]\n",
        "\n",
        "    for src, rel, dst in edge_types_to_reverse:\n",
        "        if hasattr(data[src, rel, dst], 'edge_index'):\n",
        "            reverse_edges = data[src, rel, dst].edge_index[[1, 0]]\n",
        "            rev_rel = f'rev_{rel}'\n",
        "            data[dst, rev_rel, src].edge_index = reverse_edges\n",
        "            if hasattr(data[src, rel, dst], 'edge_weight'):\n",
        "                data[dst, rev_rel, src].edge_weight = data[src, rel, dst].edge_weight\n",
        "\n",
        "    print(f'\\nConstructed graph with the following structure:')\n",
        "    print(f'Nodes: {data.node_types}')\n",
        "    print(f'Edges: {data.edge_types}')\n",
        "    print(f'\\nChecking node features:')\n",
        "\n",
        "    for node_type in data.node_types:\n",
        "        if hasattr(data[node_type], 'x'):\n",
        "            print(f'  {node_type}: {data[node_type].x.shape}')\n",
        "\n",
        "    print(f'\\nChecking edges:')\n",
        "    for edge_type in data.edge_types:\n",
        "        if hasattr(data[edge_type], 'edge_index'):\n",
        "            print(f'  {edge_type}: {data[edge_type].edge_index.shape[1]} edges')\n",
        "    return data, mappings, df_user_movie_sub\n"
      ],
      "metadata": {
        "id": "Xj_kfqjXVOAx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Active User Selection**\n",
        "\n",
        "This function identifies the most active users by rating count, ensuring the subgraph contains users with sufficient interaction data for reliable embeddings. Returns the top N user IDs sorted by activity level."
      ],
      "metadata": {
        "id": "jP9kuR8NAorN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_active_users(df_user_movie, df_user_stats, n_users=1000):\n",
        "    user_activity = df_user_movie.groupby('user_id').size().reset_index(name='rating_count')\n",
        "    user_activity = user_activity.sort_values('rating_count', ascending=False)\n",
        "    active_user_ids = user_activity.head(n_users)['user_id'].tolist()\n",
        "\n",
        "    print(f'Selected {len(active_user_ids)} most active users')\n",
        "    print(f'Minimum number of ratings: {user_activity.head(n_users)['rating_count'].min()}')\n",
        "    print(f'Maximum number of ratings: {user_activity.head(n_users)['rating_count'].max()}')\n",
        "    print(f'Average number of ratings: {user_activity.head(n_users)['rating_count'].mean():.2f}')\n",
        "\n",
        "    return active_user_ids\n"
      ],
      "metadata": {
        "id": "jukX4D09VaXn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stratified Train/Val/Test Split**\n",
        "\n",
        "Performs user-level stratified splitting while maintaining the positive (rating ≥4) vs negative interaction ratio for each user. This ensures consistent label distribution across all splits and prevents data leakage between users."
      ],
      "metadata": {
        "id": "1gdecNwBBIl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data_stratified(df_user_movie, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-9\n",
        "    train_dfs, val_dfs, test_dfs = [], [], []\n",
        "\n",
        "    for user_id, group in df_user_movie.groupby('user_id'):\n",
        "        positive = group[group['rating'] >= 4].copy()\n",
        "        negative = group[group['rating'] < 4].copy()\n",
        "\n",
        "        if len(positive) > 0:\n",
        "            pos_train, pos_temp = train_test_split(\n",
        "                positive, test_size=(val_ratio + test_ratio) / (val_ratio + test_ratio + train_ratio),\n",
        "                random_state=random_state\n",
        "            )\n",
        "            pos_val, pos_test = train_test_split(\n",
        "                pos_temp, test_size=test_ratio / (val_ratio + test_ratio),\n",
        "                random_state=random_state\n",
        "            )\n",
        "        else:\n",
        "            pos_train, pos_val, pos_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "        if len(negative) > 0:\n",
        "            neg_train, neg_temp = train_test_split(\n",
        "                negative, test_size=(val_ratio + test_ratio) / (val_ratio + test_ratio + train_ratio),\n",
        "                random_state=random_state\n",
        "            )\n",
        "            neg_val, neg_test = train_test_split(\n",
        "                neg_temp, test_size=test_ratio / (val_ratio + test_ratio),\n",
        "                random_state=random_state\n",
        "            )\n",
        "        else:\n",
        "            neg_train, neg_val, neg_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "        train_dfs.append(pd.concat([pos_train, neg_train]))\n",
        "        val_dfs.append(pd.concat([pos_val, neg_val]))\n",
        "        test_dfs.append(pd.concat([pos_test, neg_test]))\n",
        "\n",
        "    train_df = pd.concat(train_dfs, ignore_index=True)\n",
        "    val_df = pd.concat(val_dfs, ignore_index=True)\n",
        "    test_df = pd.concat(test_dfs, ignore_index=True)\n",
        "\n",
        "    print(f'Train: {len(train_df)} links ({len(train_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "    print(f'Val: {len(val_df)} links ({len(val_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "    print(f'Test: {len(test_df)} links ({len(test_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "\n",
        "    return train_df, val_df, test_df\n"
      ],
      "metadata": {
        "id": "RXKLB78ZXPEM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Graph Split Mask Assignment**\n",
        "\n",
        "Maps the stratified user-movie splits back to the graph structure by creating binary masks for each edge in the `('user', 'rates', 'movie')` relation."
      ],
      "metadata": {
        "id": "Tjt1fbFgBXR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_split_masks_to_graph(graph, train_df, val_df, test_df, mappings):\n",
        "    train_set = set(zip(train_df['user_id'], train_df['movie_id']))\n",
        "    val_set = set(zip(val_df['user_id'], val_df['movie_id']))\n",
        "    test_set = set(zip(test_df['user_id'], test_df['movie_id']))\n",
        "\n",
        "    if ('user', 'rates', 'movie') in graph.edge_types:\n",
        "        edge_index = graph['user', 'rates', 'movie'].edge_index\n",
        "        num_edges = edge_index.shape[1]\n",
        "        train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "\n",
        "        for i in range(num_edges):\n",
        "            user_idx = edge_index[0, i].item()\n",
        "            movie_idx = edge_index[1, i].item()\n",
        "            user_id = None\n",
        "            movie_id = None\n",
        "\n",
        "            for uid, uidx in mappings['user'].items():\n",
        "                if uidx == user_idx:\n",
        "                    user_id = uid\n",
        "                    break\n",
        "\n",
        "            for mid, midx in mappings['movie'].items():\n",
        "                if midx == movie_idx:\n",
        "                    movie_id = mid\n",
        "                    break\n",
        "\n",
        "            if user_id is not None and movie_id is not None:\n",
        "                edge_tuple = (user_id, movie_id)\n",
        "\n",
        "                if edge_tuple in train_set:\n",
        "                    train_mask[i] = True\n",
        "                elif edge_tuple in val_set:\n",
        "                    val_mask[i] = True\n",
        "                elif edge_tuple in test_set:\n",
        "                    test_mask[i] = True\n",
        "\n",
        "        graph['user', 'rates', 'movie'].train_mask = train_mask\n",
        "        graph['user', 'rates', 'movie'].val_mask = val_mask\n",
        "        graph['user', 'rates', 'movie'].test_mask = test_mask\n",
        "\n",
        "        print(f'Masks added:')\n",
        "        print(f'Train: {train_mask.sum().item()} edges')\n",
        "        print(f'Val: {val_mask.sum().item()} edges')\n",
        "        print(f'Test: {test_mask.sum().item()} edges')\n",
        "\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "awLi_VGrX5k2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimized Split Mask Assignment**\n",
        "\n",
        "Creates reverse ID mappings for efficient lookup and applies the same train/val/test masks to both directional and reverse user-movie edges, ensuring consistency during bidirectional message passing in GraphSAGE."
      ],
      "metadata": {
        "id": "AHtR3obLBkhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_split_masks_fast(graph, train_df, val_df, test_df, mappings):\n",
        "    reverse_mappings = {}\n",
        "    for node_type, mapping in mappings.items():\n",
        "        reverse_mappings[node_type] = {v: k for k, v in mapping.items()}\n",
        "\n",
        "    train_set = set(zip(train_df['user_id'], train_df['movie_id']))\n",
        "    val_set = set(zip(val_df['user_id'], val_df['movie_id']))\n",
        "    test_set = set(zip(test_df['user_id'], test_df['movie_id']))\n",
        "    if ('user', 'rates', 'movie') in graph.edge_types:\n",
        "        edge_index = graph['user', 'rates', 'movie'].edge_index\n",
        "        num_edges = edge_index.shape[1]\n",
        "        train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "\n",
        "        for i in range(num_edges):\n",
        "            user_idx = edge_index[0, i].item()\n",
        "            movie_idx = edge_index[1, i].item()\n",
        "            user_id = reverse_mappings['user'].get(user_idx)\n",
        "            movie_id = reverse_mappings['movie'].get(movie_idx)\n",
        "\n",
        "            if user_id is not None and movie_id is not None:\n",
        "                edge_tuple = (user_id, movie_id)\n",
        "                if edge_tuple in train_set:\n",
        "                    train_mask[i] = True\n",
        "                elif edge_tuple in val_set:\n",
        "                    val_mask[i] = True\n",
        "                elif edge_tuple in test_set:\n",
        "                    test_mask[i] = True\n",
        "\n",
        "        graph['user', 'rates', 'movie'].train_mask = train_mask\n",
        "        graph['user', 'rates', 'movie'].val_mask = val_mask\n",
        "        graph['user', 'rates', 'movie'].test_mask = test_mask\n",
        "\n",
        "        if ('movie', 'rev_rates', 'user') in graph.edge_types:\n",
        "            graph['movie', 'rev_rates', 'user'].train_mask = train_mask\n",
        "            graph['movie', 'rev_rates', 'user'].val_mask = val_mask\n",
        "            graph['movie', 'rev_rates', 'user'].test_mask = test_mask\n",
        "\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "G3TYMzkYYA_o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Graph Preparation**\n",
        "\n",
        "Performs a complete pipeline: splits user-movie interactions into train/val/test sets, assigns corresponding masks to graph edges, and precomputes negative sampling candidates for each user by excluding their rated movies."
      ],
      "metadata": {
        "id": "3bQOPnLTBq0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_graph_with_splits(subgraph, mappings, user_movie_edges, num_negatives=200):\n",
        "    train_df, val_df, test_df = split_data_stratified(\n",
        "        user_movie_edges,\n",
        "        train_ratio=0.7,\n",
        "        val_ratio=0.15,\n",
        "        test_ratio=0.15\n",
        "    )\n",
        "\n",
        "    reverse_mappings = {}\n",
        "\n",
        "    for node_type, mapping in mappings.items():\n",
        "        reverse_mappings[node_type] = {v: k for k, v in mapping.items()}\n",
        "\n",
        "    graph = add_split_masks_fast(subgraph, train_df, val_df, test_df, mappings)\n",
        "    user_train_movies = {}\n",
        "\n",
        "    for _, row in train_df.iterrows():\n",
        "        user_id = row['user_id']\n",
        "        movie_id = row['movie_id']\n",
        "\n",
        "        if user_id not in user_train_movies:\n",
        "            user_train_movies[user_id] = set()\n",
        "        user_train_movies[user_id].add(movie_id)\n",
        "\n",
        "    all_movie_ids = set(mappings['movie'].keys())\n",
        "    negative_candidates = {}\n",
        "\n",
        "    for user_id, rated_movies in user_train_movies.items():\n",
        "        candidate_movies = all_movie_ids - rated_movies\n",
        "        negative_candidates[user_id] = list(candidate_movies)\n",
        "\n",
        "    splits = {\n",
        "        'train_df': train_df,\n",
        "        'val_df': val_df,\n",
        "        'test_df': test_df,\n",
        "        'user_train_movies': user_train_movies,\n",
        "        'negative_candidates': negative_candidates,\n",
        "        'all_movie_ids': all_movie_ids,\n",
        "        'reverse_mappings': reverse_mappings\n",
        "    }\n",
        "\n",
        "    print(f'   Graph contains {graph.num_edges} edges')\n",
        "    print(f'   {len(negative_candidates)} users available for negative sampling')\n",
        "\n",
        "    return graph, splits\n"
      ],
      "metadata": {
        "id": "letjQtTRYLSy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simple Train/Val/Test Split**\n",
        "\n",
        "Performs a user-level random split of interactions without stratifying by rating. Ensures each user has at least one interaction in the training set."
      ],
      "metadata": {
        "id": "x3w10_MICE6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data_simple(df_user_movie, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    train_dfs, val_dfs, test_dfs = [], [], []\n",
        "\n",
        "    for user_id, group in df_user_movie.groupby('user_id'):\n",
        "        n = len(group)\n",
        "        if n == 0:\n",
        "            continue\n",
        "\n",
        "        n_test = max(1, int(n * test_ratio))\n",
        "        n_val = max(1, int(n * val_ratio))\n",
        "        n_train = n - n_val - n_test\n",
        "\n",
        "        if n_train <= 0:\n",
        "            n_train = 1\n",
        "            n_val = min(n - 1, n_val)\n",
        "            n_test = n - n_train - n_val\n",
        "\n",
        "        indices = np.random.permutation(n)\n",
        "\n",
        "        train_idx = indices[:n_train]\n",
        "        val_idx = indices[n_train:n_train + n_val]\n",
        "        test_idx = indices[n_train + n_val:]\n",
        "\n",
        "        train_dfs.append(group.iloc[train_idx])\n",
        "        val_dfs.append(group.iloc[val_idx])\n",
        "        test_dfs.append(group.iloc[test_idx])\n",
        "\n",
        "    train_df = pd.concat(train_dfs, ignore_index=True)\n",
        "    val_df = pd.concat(val_dfs, ignore_index=True)\n",
        "    test_df = pd.concat(test_dfs, ignore_index=True)\n",
        "\n",
        "    print(f'Train: {len(train_df)} links ({len(train_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "    print(f'Val: {len(val_df)} links ({len(val_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "    print(f'Test: {len(test_df)} links ({len(test_df) / len(df_user_movie) * 100:.1f}%)')\n",
        "\n",
        "    return train_df, val_df, test_df\n"
      ],
      "metadata": {
        "id": "TxC-UL7peHm1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "active_user_ids = get_most_active_users(\n",
        "    df_connections_user_movie,\n",
        "    df_connections_user_stats,\n",
        "    n_users=5000\n",
        ")\n",
        "\n",
        "subgraph, mappings, user_movie_edges = build_subgraph_for_users(\n",
        "    user_ids=active_user_ids,\n",
        "    df_user_movie=df_connections_user_movie,\n",
        "    df_movie_features=df_connections_movie_features,\n",
        "    df_user_stats=df_connections_user_stats,\n",
        "    df_movie_genre=df_connections_movie_genre,\n",
        "    df_movie_actor=df_connections_movie_actor,\n",
        "    df_movie_director=df_connections_movie_director,\n",
        "    df_actors=df_connections_actors,\n",
        "    df_directors=df_connections_directors,\n",
        "    df_genres=df_connections_genres,\n",
        "    num_negatives=500\n",
        ")\n",
        "\n",
        "train_df, val_df, test_df = split_data_simple(\n",
        "    user_movie_edges,\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.15,\n",
        "    test_ratio=0.15\n",
        ")\n",
        "\n",
        "reverse_mappings = {}\n",
        "for node_type, mapping in mappings.items():\n",
        "    reverse_mappings[node_type] = {v: k for k, v in mapping.items()}\n",
        "\n",
        "train_set = set(zip(train_df['user_id'], train_df['movie_id']))\n",
        "val_set = set(zip(val_df['user_id'], val_df['movie_id']))\n",
        "test_set = set(zip(test_df['user_id'], test_df['movie_id']))\n",
        "\n",
        "if ('user', 'rates', 'movie') in subgraph.edge_types:\n",
        "    edge_index = subgraph['user', 'rates', 'movie'].edge_index\n",
        "    num_edges = edge_index.shape[1]\n",
        "    train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "\n",
        "    for i in range(num_edges):\n",
        "        user_idx = edge_index[0, i].item()\n",
        "        movie_idx = edge_index[1, i].item()\n",
        "        user_id = reverse_mappings['user'].get(user_idx)\n",
        "        movie_id = reverse_mappings['movie'].get(movie_idx)\n",
        "\n",
        "        if user_id is not None and movie_id is not None:\n",
        "            edge_tuple = (user_id, movie_id)\n",
        "            if edge_tuple in train_set:\n",
        "                train_mask[i] = True\n",
        "            elif edge_tuple in val_set:\n",
        "                val_mask[i] = True\n",
        "            elif edge_tuple in test_set:\n",
        "                test_mask[i] = True\n",
        "    subgraph['user', 'rates', 'movie'].train_mask = train_mask\n",
        "    subgraph['user', 'rates', 'movie'].val_mask = val_mask\n",
        "    subgraph['user', 'rates', 'movie'].test_mask = test_mask\n",
        "\n",
        "    if ('movie', 'rev_rates', 'user') in subgraph.edge_types:\n",
        "        subgraph['movie', 'rev_rates', 'user'].train_mask = train_mask\n",
        "        subgraph['movie', 'rev_rates', 'user'].val_mask = val_mask\n",
        "        subgraph['movie', 'rev_rates', 'user'].test_mask = test_mask\n",
        "\n",
        "user_train_movies = {}\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    movie_id = row['movie_id']\n",
        "\n",
        "    if user_id not in user_train_movies:\n",
        "        user_train_movies[user_id] = set()\n",
        "    user_train_movies[user_id].add(movie_id)\n",
        "\n",
        "all_movie_ids = set(mappings['movie'].keys())\n",
        "negative_candidates = {}\n",
        "\n",
        "for user_id in active_user_ids:\n",
        "    if user_id in user_train_movies:\n",
        "        rated_movies = user_train_movies[user_id]\n",
        "        candidate_movies = all_movie_ids - rated_movies\n",
        "        negative_candidates[user_id] = list(candidate_movies)\n",
        "    else:\n",
        "        negative_candidates[user_id] = list(all_movie_ids)\n",
        "\n",
        "splits_info = {\n",
        "    'train_df': train_df,\n",
        "    'val_df': val_df,\n",
        "    'test_df': test_df,\n",
        "    'user_train_movies': user_train_movies,\n",
        "    'negative_candidates': negative_candidates,\n",
        "    'all_movie_ids': all_movie_ids,\n",
        "    'reverse_mappings': reverse_mappings,\n",
        "    'active_user_ids': active_user_ids\n",
        "}\n",
        "\n",
        "torch.save({\n",
        "    'graph': subgraph,\n",
        "    'splits': splits_info,\n",
        "    'mappings': mappings\n",
        "}, 'prepared_graph.pt')\n",
        "\n",
        "print(f'Saved to file: \\'prepared_graph.pt\\'')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVikjSJodmR4",
        "outputId": "e7e9f285-ebb2-4b79-d028-7116b1aebfb5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected 5000 most active users\n",
            "Minimum number of ratings: 52\n",
            "Maximum number of ratings: 56\n",
            "Average number of ratings: 54.28\n",
            "\n",
            "Sizes of filtered data:\n",
            "Users: 5000\n",
            "Movies: 8579\n",
            "User-movie links: 271376\n",
            "Actors: 2512\n",
            "Directors: 1600\n",
            "Genres: 20\n",
            "\n",
            "Constructed graph with the following structure:\n",
            "Nodes: ['user', 'movie', 'actor', 'director', 'genre']\n",
            "Edges: [('user', 'rates', 'movie'), ('movie', 'has_genre', 'genre'), ('movie', 'has_director', 'director'), ('movie', 'has_actor', 'actor'), ('genre', 'rev_has_genre', 'movie'), ('director', 'rev_has_director', 'movie'), ('actor', 'rev_has_actor', 'movie'), ('movie', 'rev_rates', 'user')]\n",
            "\n",
            "Checking node features:\n",
            "  user: torch.Size([5000, 3])\n",
            "  movie: torch.Size([8579, 3])\n",
            "  actor: torch.Size([2512, 5])\n",
            "  director: torch.Size([1600, 4])\n",
            "  genre: torch.Size([20, 20])\n",
            "\n",
            "Checking edges:\n",
            "  ('user', 'rates', 'movie'): 271376 edges\n",
            "  ('movie', 'has_genre', 'genre'): 21323 edges\n",
            "  ('movie', 'has_director', 'director'): 6605 edges\n",
            "  ('movie', 'has_actor', 'actor'): 32402 edges\n",
            "  ('genre', 'rev_has_genre', 'movie'): 21323 edges\n",
            "  ('director', 'rev_has_director', 'movie'): 6605 edges\n",
            "  ('actor', 'rev_has_actor', 'movie'): 32402 edges\n",
            "  ('movie', 'rev_rates', 'user'): 271376 edges\n",
            "Train: 194520 links (71.7%)\n",
            "Val: 38428 links (14.2%)\n",
            "Test: 38428 links (14.2%)\n",
            "Saved to file: 'prepared_graph.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset and DataLoaders for Training**\n",
        "\n",
        "The `RecDataset` class converts user-movie interactions into training samples with negative sampling, where each positive interaction is paired with `num_negatives` unrated movies. The `create_dataloaders` function then creates PyTorch DataLoader instances for train/val/test splits to enable batch processing during model training."
      ],
      "metadata": {
        "id": "eniD5J_QCUNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecDataset(Dataset):\n",
        "    def __init__(self, df, negative_candidates, mappings, num_negatives=10):\n",
        "        self.df = df\n",
        "        self.negative_candidates = negative_candidates\n",
        "        self.mappings = mappings\n",
        "        self.num_negatives = num_negatives\n",
        "        self.data = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            user_idx = mappings['user'][row['user_id']]\n",
        "            movie_idx = mappings['movie'][row['movie_id']]\n",
        "            self.data.append({\n",
        "                'user_idx': user_idx,\n",
        "                'movie_idx': movie_idx,\n",
        "                'rating': row['rating']\n",
        "            })\n",
        "\n",
        "        self.neg_candidates_idx = {}\n",
        "        for user_id, movie_ids in negative_candidates.items():\n",
        "            user_idx = mappings['user'][user_id]\n",
        "            self.neg_candidates_idx[user_idx] = [\n",
        "                mappings['movie'][mid] for mid in movie_ids\n",
        "            ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        user_idx = item['user_idx']\n",
        "\n",
        "        if user_idx in self.neg_candidates_idx:\n",
        "            candidates = self.neg_candidates_idx[user_idx]\n",
        "\n",
        "            if len(candidates) >= self.num_negatives:\n",
        "                neg_indices = np.random.choice(candidates, self.num_negatives, replace=False)\n",
        "            else:\n",
        "                neg_indices = np.random.choice(candidates, self.num_negatives, replace=True)\n",
        "        else:\n",
        "            all_movies = list(self.mappings['movie'].values())\n",
        "            neg_indices = np.random.choice(all_movies, self.num_negatives, replace=False)\n",
        "\n",
        "        return {\n",
        "            'user_idx': torch.tensor(user_idx, dtype=torch.long),\n",
        "            'pos_movie_idx': torch.tensor(item['movie_idx'], dtype=torch.long),\n",
        "            'neg_movie_indices': torch.tensor(neg_indices, dtype=torch.long),\n",
        "            'rating': torch.tensor(item['rating'], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "\n",
        "def create_dataloaders(splits, mappings, batch_size=32, num_negatives=10):\n",
        "    train_dataset = RecDataset(splits['train_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "    val_dataset = RecDataset(splits['val_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "    test_dataset = RecDataset(splits['test_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "PeghqLWGGIOR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Heterogeneous GraphSAGE Model**\n",
        "\n",
        "A two-layer heterogeneous GNN that projects all node types to a shared hidden space, then performs message passing along all edge types (including reversed edges) to learn user and movie embeddings. The model specifically returns user and movie node embeddings for downstream recommendation tasks."
      ],
      "metadata": {
        "id": "Pf7SAkv8CkLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HeteroSAGE(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        user_feat_dim,\n",
        "        movie_feat_dim,\n",
        "        actor_feat_dim,\n",
        "        director_feat_dim,\n",
        "        genre_feat_dim,\n",
        "        hidden_channels=64,\n",
        "        out_channels=32\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_lin = Linear(user_feat_dim, hidden_channels)\n",
        "        self.movie_lin = Linear(movie_feat_dim, hidden_channels)\n",
        "        self.actor_lin = Linear(actor_feat_dim, hidden_channels)\n",
        "        self.director_lin = Linear(director_feat_dim, hidden_channels)\n",
        "        self.genre_lin = Linear(genre_feat_dim, hidden_channels)\n",
        "\n",
        "        self.conv1 = HeteroConv({\n",
        "            ('user', 'rates', 'movie'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('movie', 'rev_rates', 'user'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('movie', 'has_genre', 'genre'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('genre', 'rev_has_genre', 'movie'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('movie', 'has_director', 'director'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('director', 'rev_has_director', 'movie'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('movie', 'has_actor', 'actor'): SAGEConv(hidden_channels, hidden_channels),\n",
        "            ('actor', 'rev_has_actor', 'movie'): SAGEConv(hidden_channels, hidden_channels),\n",
        "        }, aggr='sum')\n",
        "\n",
        "        self.conv2 = HeteroConv({\n",
        "            ('user', 'rates', 'movie'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('movie', 'rev_rates', 'user'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('movie', 'has_genre', 'genre'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('genre', 'rev_has_genre', 'movie'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('movie', 'has_director', 'director'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('director', 'rev_has_director', 'movie'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('movie', 'has_actor', 'actor'): SAGEConv(hidden_channels, out_channels),\n",
        "            ('actor', 'rev_has_actor', 'movie'): SAGEConv(hidden_channels, out_channels),\n",
        "        }, aggr='sum')\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        x_dict = {\n",
        "            'user': self.user_lin(x_dict['user']),\n",
        "            'movie': self.movie_lin(x_dict['movie']),\n",
        "            'actor': self.actor_lin(x_dict['actor']),\n",
        "            'director': self.director_lin(x_dict['director']),\n",
        "            'genre': self.genre_lin(x_dict['genre']),\n",
        "        }\n",
        "\n",
        "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
        "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
        "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
        "\n",
        "        return x_dict['user'], x_dict['movie']\n"
      ],
      "metadata": {
        "id": "8rEbSpVdzDmO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Pipeline with Evaluation**\n",
        "\n",
        "### Data Loading & Batching\n",
        "- **RecDataset**: Converts user-movie interactions to training samples with negative sampling, ensuring each positive item is paired with `num_negatives` unrated movies.\n",
        "- **DataLoaders**: Creates dataloaders for train/val/test splits with proper batching and memory pinning.\n",
        "\n",
        "### Training Infrastructure\n",
        "- **Model Forward**: Extracts user and movie embeddings from the heterogeneous graph using train/val edge masks.\n",
        "- **Loss Computation**: Computes Bayesian Personalized Ranking (BPR) loss by comparing positive vs negative movie scores.\n",
        "- **Training Loop**: Implements standard training/validation cycles with gradient updates and loss tracking.\n",
        "\n",
        "### Evaluation Framework\n",
        "- **Ranking Metrics**: Computes precision@k, recall@k, F1@k, NDCG@k, and MAP@k for multiple k values.\n",
        "- **Classification Metrics**: Calculates accuracy, precision, recall, F1, and AUC-ROC scores.\n",
        "\n",
        "### Complete Training Function\n",
        "- **End-to-End Pipeline**: Loads prepared graph data, initializes model, runs training epochs with periodic evaluation, and returns final metrics."
      ],
      "metadata": {
        "id": "aEMWy1sAC8wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecDataset(Dataset):\n",
        "    def __init__(self, df, negative_candidates, mappings, num_negatives=10, rng_seed=None):\n",
        "        self.df = df\n",
        "        self.negative_candidates = negative_candidates\n",
        "        self.mappings = mappings\n",
        "        self.num_negatives = num_negatives\n",
        "        self.rng = np.random.default_rng(rng_seed)\n",
        "        self.data = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            user_idx = mappings['user'][row['user_id']]\n",
        "            movie_idx = mappings['movie'][row['movie_id']]\n",
        "\n",
        "            self.data.append({\n",
        "                'user_idx': int(user_idx),\n",
        "                'movie_idx': int(movie_idx),\n",
        "                'rating': float(row['rating'])\n",
        "            })\n",
        "\n",
        "        self.neg_candidates_idx = {}\n",
        "\n",
        "        for user_id, movie_ids in negative_candidates.items():\n",
        "            user_idx = mappings['user'][user_id]\n",
        "            self.neg_candidates_idx[int(user_idx)] = [\n",
        "                int(mappings['movie'][mid]) for mid in movie_ids\n",
        "            ]\n",
        "\n",
        "        self._all_movie_indices = list(mappings['movie'].values())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        user_idx = item['user_idx']\n",
        "\n",
        "        if user_idx in self.neg_candidates_idx and len(self.neg_candidates_idx[user_idx]) > 0:\n",
        "            candidates = self.neg_candidates_idx[user_idx]\n",
        "            if len(candidates) >= self.num_negatives:\n",
        "                neg_indices = self.rng.choice(candidates, self.num_negatives, replace=False)\n",
        "            else:\n",
        "                neg_indices = self.rng.choice(candidates, self.num_negatives, replace=True)\n",
        "        else:\n",
        "            if len(self._all_movie_indices) >= self.num_negatives:\n",
        "                neg_indices = self.rng.choice(self._all_movie_indices, self.num_negatives, replace=False)\n",
        "            else:\n",
        "                neg_indices = self.rng.choice(self._all_movie_indices, self.num_negatives, replace=True)\n",
        "\n",
        "        return {\n",
        "            'user_idx': torch.tensor(user_idx, dtype=torch.long),\n",
        "            'pos_movie_idx': torch.tensor(item['movie_idx'], dtype=torch.long),\n",
        "            'neg_movie_indices': torch.tensor(neg_indices, dtype=torch.long),\n",
        "            'rating': torch.tensor(item['rating'], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "\n",
        "def dict_collate_fn(batch: List[Dict[str, torch.Tensor]]):\n",
        "    collated = {}\n",
        "    if len(batch) == 0:\n",
        "        return collated\n",
        "\n",
        "    keys = batch[0].keys()\n",
        "\n",
        "    for k in keys:\n",
        "        collated[k] = torch.stack([d[k] for d in batch], dim=0)\n",
        "    return collated\n",
        "\n",
        "\n",
        "def create_dataloaders(splits, mappings, batch_size=32, num_negatives=10, num_workers=2,\n",
        "                       pin_memory: bool = True):\n",
        "    train_dataset = RecDataset(splits['train_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "    val_dataset = RecDataset(splits['val_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "    test_dataset = RecDataset(splits['test_df'], splits['negative_candidates'], mappings, num_negatives)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        collate_fn=dict_collate_fn, num_workers=num_workers, pin_memory=pin_memory\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False,\n",
        "        collate_fn=dict_collate_fn, num_workers=num_workers, pin_memory=pin_memory\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False,\n",
        "        collate_fn=dict_collate_fn, num_workers=num_workers, pin_memory=pin_memory\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _model_device(model: torch.nn.Module):\n",
        "    try:\n",
        "        return next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def get_embeddings_with_masks(model, graph, use_train_mask=True):\n",
        "    device = _model_device(model)\n",
        "    x_dict_on_device = {}\n",
        "\n",
        "    for k, v in graph.x_dict.items():\n",
        "        x_dict_on_device[k] = v.to(device)\n",
        "    edge_index_dict = {}\n",
        "\n",
        "    for edge_type in graph.edge_types:\n",
        "        data_edge = graph[edge_type]\n",
        "        if use_train_mask and hasattr(data_edge, 'train_mask'):\n",
        "            edge_index = data_edge.edge_index[:, data_edge.train_mask]\n",
        "            edge_index_dict[edge_type] = edge_index.to(device)\n",
        "        else:\n",
        "            edge_index_dict[edge_type] = data_edge.edge_index.to(device)\n",
        "\n",
        "    user_emb, movie_emb = model(x_dict_on_device, edge_index_dict)\n",
        "    user_emb = user_emb.to(device)\n",
        "    movie_emb = movie_emb.to(device)\n",
        "\n",
        "    return user_emb, movie_emb\n",
        "\n",
        "\n",
        "def batch_loss(model, graph, batch, use_train_mask=True):\n",
        "    user_emb, movie_emb = get_embeddings_with_masks(model, graph, use_train_mask)\n",
        "    user_emb_batch = user_emb[batch['user_idx']]\n",
        "    pos_movie_emb = movie_emb[batch['pos_movie_idx']]\n",
        "    neg_movie_emb = movie_emb[batch['neg_movie_indices']]\n",
        "\n",
        "    pos_scores = torch.sum(user_emb_batch * pos_movie_emb, dim=1)\n",
        "    neg_scores = torch.sum(user_emb_batch.unsqueeze(1) * neg_movie_emb, dim=2)\n",
        "\n",
        "    pos_targets = torch.ones_like(pos_scores)\n",
        "    neg_targets = torch.zeros_like(neg_scores)\n",
        "\n",
        "    all_scores = torch.cat([pos_scores.unsqueeze(1), neg_scores], dim=1)\n",
        "    all_targets = torch.cat([pos_targets.unsqueeze(1), neg_targets], dim=1)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    return loss_fn(all_scores, all_targets)\n",
        "\n",
        "\n",
        "def simple_train_epoch(model, graph, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
        "        optimizer.zero_grad()\n",
        "        loss = batch_loss(model, graph, batch, use_train_mask=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / max(1, num_batches)\n",
        "\n",
        "\n",
        "def validate(model, graph, val_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
        "            loss = batch_loss(model, graph, batch, use_train_mask=False)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    return total_loss / max(1, num_batches)\n",
        "\n",
        "\n",
        "def compute_ranking_metrics(\n",
        "        model,\n",
        "        graph,\n",
        "        splits,\n",
        "        mappings,\n",
        "        k_list: List[int] = [5, 10, 20],\n",
        "        max_users: int = 200,\n",
        "        max_negatives_per_user: int = 100,\n",
        "        positive_threshold: float = 4.0\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    device = _model_device(model)\n",
        "    user_emb, movie_emb = get_embeddings_with_masks(model, graph, use_train_mask=False)\n",
        "    val_users = splits['val_df']['user_id'].unique()\n",
        "\n",
        "    if len(val_users) > max_users:\n",
        "        val_users = np.random.choice(val_users, max_users, replace=False)\n",
        "\n",
        "    metrics_accum = {f'precision@{k}': [] for k in k_list}\n",
        "    metrics_accum.update({f'recall@{k}': [] for k in k_list})\n",
        "    metrics_accum.update({f'f1@{k}': [] for k in k_list})\n",
        "    metrics_accum.update({f'ndcg@{k}': [] for k in k_list})\n",
        "    metrics_accum.update({f'map@{k}': [] for k in k_list})\n",
        "\n",
        "    all_true = []\n",
        "    all_pred = []\n",
        "    all_pred_proba = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for user_id in val_users:\n",
        "            if user_id not in mappings['user']:\n",
        "                continue\n",
        "\n",
        "            user_idx = mappings['user'][user_id]\n",
        "            user_val_rows = splits['val_df'][splits['val_df']['user_id'] == user_id]\n",
        "            user_val_positives = user_val_rows[user_val_rows['rating'] >= positive_threshold]['movie_id'].tolist()\n",
        "\n",
        "            if len(user_val_positives) == 0:\n",
        "                continue\n",
        "\n",
        "            if user_id in splits['negative_candidates']:\n",
        "                neg_cands = splits['negative_candidates'][user_id]\n",
        "                if len(neg_cands) > max_negatives_per_user:\n",
        "                    neg_cands = list(np.random.choice(neg_cands, max_negatives_per_user, replace=False))\n",
        "            else:\n",
        "                neg_cands = [mid for mid in splits['all_movie_ids'] if\n",
        "                             mid not in splits['user_train_movies'].get(user_id, set())]\n",
        "\n",
        "                if len(neg_cands) > max_negatives_per_user:\n",
        "                    neg_cands = list(np.random.choice(neg_cands, max_negatives_per_user, replace=False))\n",
        "\n",
        "            if len(neg_cands) == 0:\n",
        "                continue\n",
        "\n",
        "            candidate_movies = list(neg_cands) + list(user_val_positives)\n",
        "            candidate_movies = [mid for mid in candidate_movies if mid in mappings['movie']]\n",
        "\n",
        "            if len(candidate_movies) == 0:\n",
        "                continue\n",
        "\n",
        "            candidate_indices = [mappings['movie'][mid] for mid in candidate_movies]\n",
        "            user_emb_single = user_emb[user_idx:user_idx + 1]\n",
        "            candidate_emb = movie_emb[candidate_indices]\n",
        "\n",
        "            scores = torch.matmul(user_emb_single, candidate_emb.T).squeeze(0)\n",
        "            probs = torch.sigmoid(scores).cpu().numpy()\n",
        "            relevance = np.array([1 if mid in user_val_positives else 0 for mid in candidate_movies], dtype=int)\n",
        "            binary_preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            all_true.extend(relevance.tolist())\n",
        "            all_pred.extend(binary_preds.tolist())\n",
        "            all_pred_proba.extend(probs.tolist())\n",
        "\n",
        "            sorted_idx = np.argsort(-scores.cpu().numpy())\n",
        "            sorted_relevance = relevance[sorted_idx]\n",
        "            sorted_scores_for_ndcg = scores.cpu().numpy()[sorted_idx]\n",
        "\n",
        "            for k in k_list:\n",
        "                if len(sorted_relevance) < 1:\n",
        "                    continue\n",
        "\n",
        "                topk = sorted_relevance[:k]\n",
        "                precision_at_k = topk.sum() / k\n",
        "                recall_at_k = topk.sum() / max(1, relevance.sum())\n",
        "\n",
        "                if precision_at_k + recall_at_k > 0:\n",
        "                    f1_at_k = 2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k)\n",
        "                else:\n",
        "                    f1_at_k = 0.0\n",
        "\n",
        "                metrics_accum[f'precision@{k}'].append(precision_at_k)\n",
        "                metrics_accum[f'recall@{k}'].append(recall_at_k)\n",
        "                metrics_accum[f'f1@{k}'].append(f1_at_k)\n",
        "\n",
        "                try:\n",
        "                    ndcg_at_k = ndcg_score([relevance], [scores.cpu().numpy()], k=k)\n",
        "                except Exception:\n",
        "                    ndcg_at_k = 0.0\n",
        "\n",
        "                metrics_accum[f'ndcg@{k}'].append(ndcg_at_k)\n",
        "                map_at_k = 0.0\n",
        "                num_relevant = 0\n",
        "\n",
        "                for i in range(min(k, len(sorted_relevance))):\n",
        "                    if sorted_relevance[i] == 1:\n",
        "                        num_relevant += 1\n",
        "                        map_at_k += num_relevant / (i + 1)\n",
        "\n",
        "                denom = min(relevance.sum(), k) if relevance.sum() > 0 else 1\n",
        "                map_at_k = map_at_k / denom\n",
        "                metrics_accum[f'map@{k}'].append(map_at_k)\n",
        "\n",
        "    avg_metrics = {}\n",
        "    for k in k_list:\n",
        "        for mname in ['precision', 'recall', 'f1', 'ndcg', 'map']:\n",
        "            key = f'{mname}@{k}'\n",
        "            vals = metrics_accum.get(key, [])\n",
        "            avg_metrics[key] = float(np.mean(vals)) if len(vals) > 0 else 0.0\n",
        "\n",
        "    if len(all_true) > 0:\n",
        "        avg_metrics['accuracy'] = float(accuracy_score(all_true, all_pred))\n",
        "        avg_metrics['precision'] = float(precision_score(all_true, all_pred, zero_division=0))\n",
        "        avg_metrics['recall'] = float(recall_score(all_true, all_pred, zero_division=0))\n",
        "        avg_metrics['f1'] = float(f1_score(all_true, all_pred, zero_division=0))\n",
        "\n",
        "        try:\n",
        "            avg_metrics['auc_roc'] = float(roc_auc_score(all_true, all_pred_proba))\n",
        "        except Exception:\n",
        "            avg_metrics['auc_roc'] = 0.0\n",
        "    else:\n",
        "        avg_metrics.update({\n",
        "            'accuracy': 0.0,\n",
        "            'precision': 0.0,\n",
        "            'recall': 0.0,\n",
        "            'f1': 0.0,\n",
        "            'auc_roc': 0.0\n",
        "        })\n",
        "\n",
        "    return avg_metrics\n",
        "\n",
        "\n",
        "def evaluate(model, graph, splits, mappings, k_list=[5, 10, 20], max_users=500, max_negatives_per_user=100):\n",
        "    metrics = compute_ranking_metrics(model, graph, splits, mappings, k_list=k_list, max_users=max_users,\n",
        "                                      max_negatives_per_user=max_negatives_per_user)\n",
        "\n",
        "    print('\\nClassification metrics:')\n",
        "    print(f'Accuracy:  {metrics[\"accuracy\"]:.4f}')\n",
        "    print(f'Precision: {metrics[\"precision\"]:.4f}')\n",
        "    print(f'Recall:    {metrics[\"recall\"]:.4f}')\n",
        "    print(f'F1-score:  {metrics[\"f1\"]:.4f}')\n",
        "    print(f'AUC-ROC:   {metrics[\"auc_roc\"]:.4f}')\n",
        "\n",
        "    print('\\nRanking metrics:')\n",
        "    for k in k_list:\n",
        "        print(f\"@k={k}: Precision: {metrics[f'precision@{k}']:.4f}, Recall: {metrics[f'recall@{k}']:.4f}\")\n",
        "        print(f\"F1: {metrics[f'f1@{k}']:.4f}, NDCG: {metrics[f'ndcg@{k}']:.4f}, MAP: {metrics[f'map@{k}']:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train(prepared_path='prepared_graph.pt', epochs=5, batch_size=32, eval_every=2, k_list=[5, 10, 20]):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    use_pin_memory = device.type == 'cuda'\n",
        "    print(f'Device: {device}, pin_memory={use_pin_memory}')\n",
        "\n",
        "    loaded_data = torch.load(prepared_path, map_location='cpu', weights_only=False)\n",
        "    graph = loaded_data['graph']\n",
        "    splits = loaded_data['splits']\n",
        "    mappings = loaded_data['mappings']\n",
        "\n",
        "    user_feat_dim = graph['user'].x.shape[1]\n",
        "    movie_feat_dim = graph['movie'].x.shape[1]\n",
        "    actor_feat_dim = graph['actor'].x.shape[1]\n",
        "    director_feat_dim = graph['director'].x.shape[1]\n",
        "    genre_feat_dim = graph['genre'].x.shape[1]\n",
        "\n",
        "    model = HeteroSAGE(\n",
        "          user_feat_dim=user_feat_dim,\n",
        "          movie_feat_dim=movie_feat_dim,\n",
        "          actor_feat_dim=actor_feat_dim,\n",
        "          director_feat_dim=director_feat_dim,\n",
        "          genre_feat_dim=genre_feat_dim,\n",
        "          hidden_channels=64,\n",
        "          out_channels=32\n",
        "    )\n",
        "    train_loader, val_loader, _ = create_dataloaders(\n",
        "        splits, mappings, batch_size=batch_size, num_negatives=10,\n",
        "        pin_memory=use_pin_memory\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    try:\n",
        "        graph = graph.to(device)\n",
        "    except Exception:\n",
        "        print('graph.to(device) not available')\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    history = {'train_loss': [], 'val_loss': [], 'metrics': []}\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss = simple_train_epoch(model, graph, train_loader, optimizer, device)\n",
        "        val_loss = validate(model, graph, val_loader, device)\n",
        "\n",
        "        if (epoch + 1) % eval_every == 0 or epoch == epochs - 1:\n",
        "            print(f'\\nEvaluating metrics at epoch {epoch + 1}...')\n",
        "            metrics = evaluate(\n",
        "                model,\n",
        "                graph,\n",
        "                splits,\n",
        "                mappings,\n",
        "                k_list=k_list,\n",
        "                max_users=500,\n",
        "                max_negatives_per_user=200)\n",
        "            history['metrics'].append(metrics)\n",
        "        else:\n",
        "            metrics = None\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        if metrics:\n",
        "            print(f'Epoch {epoch + 1}/{epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "            print(\n",
        "                f\"Sample: Precision@10: {metrics.get('precision@10', 0):.4f}, NDCG@10: {metrics.get('ndcg@10', 0):.4f}\")\n",
        "        else:\n",
        "            print(f'Epoch {epoch + 1}/{epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    print('\\nFinal evaluation on TEST set...')\n",
        "\n",
        "    final_metrics = compute_ranking_metrics(\n",
        "        model, graph,\n",
        "        {**splits, 'val_df': splits['test_df']},\n",
        "        mappings,\n",
        "        k_list=k_list,\n",
        "        max_users=min(500, len(splits['test_df']['user_id'].unique())),\n",
        "        max_negatives_per_user=200\n",
        "    )\n",
        "    print('Final test metrics (subset):')\n",
        "    print(f\"  Precision@10: {final_metrics.get('precision@10', 0):.4f}\")\n",
        "    print(f\"  Recall@10:    {final_metrics.get('recall@10', 0):.4f}\")\n",
        "    print(f\"  NDCG@10:      {final_metrics.get('ndcg@10', 0):.4f}\")\n",
        "    print(f\"  AUC-ROC:      {final_metrics.get('auc_roc', 0):.4f}\")\n",
        "    return model, history, final_metrics\n",
        "\n",
        "\n",
        "model, history, final_metrics = train(\n",
        "    prepared_path='prepared_graph.pt',\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    eval_every=2,\n",
        "    k_list=[5, 10, 20]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "387ca03e8d7b4201b22660f462482644",
            "07b5334f705f436fa7375cf697d9393c",
            "e04ffa10e4f144c6bcca8341950f40bd",
            "e7e2a464d8b647318044b21f7fe957ca",
            "0dfdf9ed96514a2bad0b12665b7ed313",
            "79f6b15cfad547178ad2007b9bcb6ed5",
            "92448b556e75482f99e53cb4a6bdbc6b",
            "34cd9d216e4945679d69f1f384d1a032",
            "b929c1e303f749319572b352f3ba7f4f",
            "039d1e1514ff4c908fbf366b8e334de3",
            "43be87711b4a4720bc9ec63ef3afd7d4"
          ]
        },
        "id": "dI1d2X6GT5P9",
        "outputId": "29d7058b-2f79-4d7c-cf95-81bd38ae22df"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda, pin_memory=True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "387ca03e8d7b4201b22660f462482644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss: 0.1538, Val Loss: 0.1440\n",
            "\n",
            "Evaluating metrics at epoch 2...\n",
            "\n",
            "Classification metrics:\n",
            "Accuracy:  0.9712\n",
            "Precision: 0.4177\n",
            "Recall:    0.6720\n",
            "F1-score:  0.5152\n",
            "AUC-ROC:   0.9671\n",
            "\n",
            "Ranking metrics:\n",
            "@k=5: Precision: 0.4960, Recall: 0.5603\n",
            "F1: 0.5020, NDCG: 0.6062, MAP: 0.4953\n",
            "@k=10: Precision: 0.3405, Recall: 0.7390\n",
            "F1: 0.4496, NDCG: 0.6672, MAP: 0.5398\n",
            "@k=20: Precision: 0.2009, Recall: 0.8616\n",
            "F1: 0.3181, NDCG: 0.7197, MAP: 0.5751\n",
            "Epoch 2/10: Train Loss: 0.1350, Val Loss: 0.1339\n",
            "Sample: Precision@10: 0.3405, NDCG@10: 0.6672\n",
            "Epoch 3/10: Train Loss: 0.1293, Val Loss: 0.1318\n",
            "\n",
            "Evaluating metrics at epoch 4...\n",
            "\n",
            "Classification metrics:\n",
            "Accuracy:  0.9725\n",
            "Precision: 0.4351\n",
            "Recall:    0.6499\n",
            "F1-score:  0.5212\n",
            "AUC-ROC:   0.9694\n",
            "\n",
            "Ranking metrics:\n",
            "@k=5: Precision: 0.4929, Recall: 0.5554\n",
            "F1: 0.4976, NDCG: 0.6083, MAP: 0.5004\n",
            "@k=10: Precision: 0.3428, Recall: 0.7460\n",
            "F1: 0.4520, NDCG: 0.6727, MAP: 0.5446\n",
            "@k=20: Precision: 0.2046, Recall: 0.8732\n",
            "F1: 0.3231, NDCG: 0.7278, MAP: 0.5827\n",
            "Epoch 4/10: Train Loss: 0.1260, Val Loss: 0.1262\n",
            "Sample: Precision@10: 0.3428, NDCG@10: 0.6727\n",
            "Epoch 5/10: Train Loss: 0.1238, Val Loss: 0.1269\n",
            "\n",
            "Evaluating metrics at epoch 6...\n",
            "\n",
            "Classification metrics:\n",
            "Accuracy:  0.9727\n",
            "Precision: 0.4570\n",
            "Recall:    0.6767\n",
            "F1-score:  0.5456\n",
            "AUC-ROC:   0.9710\n",
            "\n",
            "Ranking metrics:\n",
            "@k=5: Precision: 0.5248, Recall: 0.5641\n",
            "F1: 0.5190, NDCG: 0.6436, MAP: 0.5364\n",
            "@k=10: Precision: 0.3673, Recall: 0.7581\n",
            "F1: 0.4772, NDCG: 0.7047, MAP: 0.5777\n",
            "@k=20: Precision: 0.2173, Recall: 0.8818\n",
            "F1: 0.3403, NDCG: 0.7594, MAP: 0.6172\n",
            "Epoch 6/10: Train Loss: 0.1220, Val Loss: 0.1255\n",
            "Sample: Precision@10: 0.3673, NDCG@10: 0.7047\n",
            "Epoch 7/10: Train Loss: 0.1209, Val Loss: 0.1264\n",
            "\n",
            "Evaluating metrics at epoch 8...\n",
            "\n",
            "Classification metrics:\n",
            "Accuracy:  0.9728\n",
            "Precision: 0.4333\n",
            "Recall:    0.6979\n",
            "F1-score:  0.5346\n",
            "AUC-ROC:   0.9734\n",
            "\n",
            "Ranking metrics:\n",
            "@k=5: Precision: 0.5130, Recall: 0.5946\n",
            "F1: 0.5246, NDCG: 0.6381, MAP: 0.5307\n",
            "@k=10: Precision: 0.3462, Recall: 0.7743\n",
            "F1: 0.4606, NDCG: 0.6992, MAP: 0.5735\n",
            "@k=20: Precision: 0.2054, Recall: 0.8947\n",
            "F1: 0.3257, NDCG: 0.7519, MAP: 0.6110\n",
            "Epoch 8/10: Train Loss: 0.1197, Val Loss: 0.1237\n",
            "Sample: Precision@10: 0.3462, NDCG@10: 0.6992\n",
            "Epoch 9/10: Train Loss: 0.1191, Val Loss: 0.1224\n",
            "\n",
            "Evaluating metrics at epoch 10...\n",
            "\n",
            "Classification metrics:\n",
            "Accuracy:  0.9739\n",
            "Precision: 0.4501\n",
            "Recall:    0.6650\n",
            "F1-score:  0.5369\n",
            "AUC-ROC:   0.9705\n",
            "\n",
            "Ranking metrics:\n",
            "@k=5: Precision: 0.5029, Recall: 0.5596\n",
            "F1: 0.5077, NDCG: 0.6178, MAP: 0.5063\n",
            "@k=10: Precision: 0.3477, Recall: 0.7551\n",
            "F1: 0.4600, NDCG: 0.6858, MAP: 0.5561\n",
            "@k=20: Precision: 0.2052, Recall: 0.8794\n",
            "F1: 0.3252, NDCG: 0.7389, MAP: 0.5925\n",
            "Epoch 10/10: Train Loss: 0.1182, Val Loss: 0.1227\n",
            "Sample: Precision@10: 0.3477, NDCG@10: 0.6858\n",
            "\n",
            "Final evaluation on TEST set...\n",
            "Final test metrics (subset):\n",
            "  Precision@10: 0.3570\n",
            "  Recall@10:    0.7892\n",
            "  NDCG@10:      0.7291\n",
            "  AUC-ROC:      0.9743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(final_metrics, columns=['Metric', 'Value'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8UR9jFOiIwyd",
        "outputId": "7091d450-9026-4902-ce48-4df0c04266fb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Metric, Value]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fad9be6-baed-4736-a345-6ae3ecba0bf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fad9be6-baed-4736-a345-6ae3ecba0bf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fad9be6-baed-4736-a345-6ae3ecba0bf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fad9be6-baed-4736-a345-6ae3ecba0bf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = (pd.Series(final_metrics)\n",
        "        .rename_axis('metric_at_k')\n",
        "        .reset_index(name='value'))\n",
        "df.sort_values('metric_at_k', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "fZ1tIbngI_FY",
        "outputId": "9bed8643-d3bd-4991-f34e-7975a1ddaa06"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     metric_at_k     value\n",
              "1       recall@5  0.603632\n",
              "11     recall@20  0.912118\n",
              "6      recall@10  0.789215\n",
              "17        recall  0.700623\n",
              "0    precision@5  0.525820\n",
              "10  precision@20  0.209016\n",
              "5   precision@10  0.356967\n",
              "16     precision  0.450386\n",
              "3         ndcg@5  0.663563\n",
              "13       ndcg@20  0.781258\n",
              "8        ndcg@10  0.729064\n",
              "4          map@5  0.558192\n",
              "14        map@20  0.641516\n",
              "9         map@10  0.604737\n",
              "2           f1@5  0.539051\n",
              "12         f1@20  0.332461\n",
              "7          f1@10  0.475382\n",
              "18            f1  0.548303\n",
              "19       auc_roc  0.974252\n",
              "15      accuracy  0.973997"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52e38e3a-b82a-4459-acc2-f7cef3809fc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric_at_k</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recall@5</td>\n",
              "      <td>0.603632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>recall@20</td>\n",
              "      <td>0.912118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recall@10</td>\n",
              "      <td>0.789215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.700623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>precision@5</td>\n",
              "      <td>0.525820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>precision@20</td>\n",
              "      <td>0.209016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>precision@10</td>\n",
              "      <td>0.356967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.450386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ndcg@5</td>\n",
              "      <td>0.663563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ndcg@20</td>\n",
              "      <td>0.781258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ndcg@10</td>\n",
              "      <td>0.729064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>map@5</td>\n",
              "      <td>0.558192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>map@20</td>\n",
              "      <td>0.641516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>map@10</td>\n",
              "      <td>0.604737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f1@5</td>\n",
              "      <td>0.539051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>f1@20</td>\n",
              "      <td>0.332461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>f1@10</td>\n",
              "      <td>0.475382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>f1</td>\n",
              "      <td>0.548303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>auc_roc</td>\n",
              "      <td>0.974252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.973997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52e38e3a-b82a-4459-acc2-f7cef3809fc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52e38e3a-b82a-4459-acc2-f7cef3809fc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52e38e3a-b82a-4459-acc2-f7cef3809fc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1757e452-69ca-4d6c-93a7-6c36bf1483c9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1757e452-69ca-4d6c-93a7-6c36bf1483c9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1757e452-69ca-4d6c-93a7-6c36bf1483c9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"metric_at_k\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"recall@5\",\n          \"f1\",\n          \"f1@20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20606949962280385,\n        \"min\": 0.20901639344262296,\n        \"max\": 0.9742518908760727,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.6036316029143899,\n          0.5483028720626631,\n          0.3324610212767364\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}